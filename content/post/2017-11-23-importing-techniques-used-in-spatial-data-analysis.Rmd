---
title: Importing Techniques Used in Spatial Data Analysis
author: sumendar
date: '2017-11-23'
slug: importing-techniques-used-in-spatial-data-analysis
categories: []
tags: []
output: 
  html_document: 
    self_contained: no
    toc: yes
---

**In this post we are going to take a look at various data importing techniques used for spatial data analysis**

## Importing Data from Tables (read.table)

* Opening data
* Importing csv files
* Checking the data structure for consistency

**Accessing and importing open access environmental data is a crucial skill for data scientists. This section teaches you how to download data from the Web, import it in R and check it for consistency.**

**In this section, we are going to take a look at...**

* Download open-access data from the USGS website
* Import it in R using read.table
* Check its structure to start exploring the data




```{r}
#Set the URL with the CSV Files
URL <- "http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_day.csv"
```

```{r}
#Load the CSV File
Data <- read.table(file=URL, 
                   sep=",", 
                   header=TRUE, 
                   na.string="")
```

```{r eval=FALSE, include=TRUE}
#Help function
help(read.table)
```

```{r}
#Examining the data
str(Data)
```

##Downloading Open Data from FTP Sites 

**Often times, datasets are provided for free, but on FTP, websites and practitioners need to be able to access them. R is perfectly capable of downloading and importing data from FTP sites.**

**In this section, we are going to take a look at...**

* Understand the basics of downloading data in R
* Download the data with the download.file function
* Learn how to handle compressed formats

```{r}
#Load required packages
library(RCurl)
library(XML)
```


```{r}
#Create a list with all the files on the FTP site
list <- getURL("ftp://ftp.ncdc.noaa.gov/pub/data/gsod/2016/", 
               dirlistonly = TRUE) 
```

```{r}
#Clean the list 
FileList <- strsplit(list, split="\r\n")
```

```{r}
#Create a new directory where to download these files
DIR <- paste(getwd(),"/NOAAFiles",sep="")
dir.create(DIR)
```


```{r eval=FALSE, include=TRUE}
#Loop to download the files
for(FileName in unlist(FileList)){
  URL <- paste0("ftp://ftp.ncdc.noaa.gov/pub/data/gsod/2016/",FileName)
  download.file(URL, destfile=paste0(DIR,"/",FileName), method="auto", 
                mode="wb")
}
```

```{r eval=FALSE, include=TRUE}
#A more elegant way
DownloadFile <- function(x){
  URL <- paste0("ftp://ftp.ncdc.noaa.gov/pub/data/gsod/2016/",x)
  download.file(URL, destfile=paste0(DIR,"/",x), method="auto", mode="wb")
}
lapply(unlist(FileList)[1:5], DownloadFile)
```

```{r eval=FALSE, include=TRUE}
#Dowload a compressed file
URL <- "ftp://ftp.ncdc.noaa.gov/pub/data/gsod/2015/gsod_2015.tar"
download.file(URL, destfile=paste0(DIR,"/gsod_2015.tar"),
              method="auto",mode="wb")

untar(paste0(getwd(),"/NOAAFiles/","gsod_2015.tar"), 
      exdir=paste0(getwd(),"/NOAAFiles"))
```


```{r eval=FALSE, include=TRUE}
help(unzip)
#For more information on the full experiment please visit:
#http://r-video-tutorial.blogspot.ch/2014/12/accessing-cleaning-and-plotting-noaa.html
```

##Fixed-Width Format
**In this section, we are going to take a look at...**

* Creating a list of files in a folder
* Opening data compressed in gzip
* Opening data in fixed width format

```{r include=FALSE, eval=TRUE }
getwd()
#Setting the working directory
setwd("./NOAAFiles")
getwd()
#Create a list with all the files in the directory
FileList <- list.files(path=".", pattern=".gz", full.names=FALSE)
```

```{r include=TRUE, eval=FALSE}
help(list.files)
```

```{r}
setwd("./NOAAFiles")
#Open the first file in the list
data <- read.fwf(gzfile(FileList[1],open="rt"),
                 header=F,
                 skip=1,
                 widths=c(6,1,5,2,8,4,4,108))
```

```{r}
str(data)
```


```{r}
#Clean it from unwanted columns
data.clean <- data[,c("V1", "V3", "V5", "V7")]
```

```{r}
str(data.clean)
```


```{r}
#Change the names of the columns
names(data.clean) <- c("STN", "WBAN", "YEARMODA", "TEMP")
```

```{r}
head(data.clean)
```

##Importing with read.lines (The Last Resort)
Some data cannot be open with neither `read.table` nor `read.fwf`  
In this desperate cases in *`readLines`* can help  
**In this section, we are going to take a look at...**
*
```{r}
#Download the data from the FTP site
URL <- "ftp://ftp.ncdc.noaa.gov/pub/data/noaa/2015/010231-99999-2015.gz"
FileName <- "010231-99999-2015.gz"
download.file(URL, destfile=paste0(getwd(),"/",FileName), method="auto", mode="wb")
```

```{r}
data.strings <- readLines(gzfile(FileName, open="rt"))

head(data.strings)
```


#Functions for test
```{r}
Ext.Latitude <- function(x){
  substr(x, start=29, stop=34)
}
```

#Functions for test 2
```{r}
Ext.Longitude <- function(x){
  substr(x, start=35, stop=41)
}
```

#Functions for test 2
```{r}
Ext.Temp <- function(x){
  substr(x, start=88, stop=92)
}
```

##lapply function usage
```{r}
LAT <- lapply(data.strings, Ext.Latitude)
LON <- lapply(data.strings, Ext.Longitude)
TEMP <- lapply(data.strings, Ext.Temp)
```

#Create a data.frame we can use for data analysis
```{r}
DATA <- data.frame(Latitude=as.numeric(unlist(LAT))/1000,
                   Longitude=as.numeric(unlist(LON))/1000,
                   Temperature=as.numeric(unlist(TEMP))/10)
```

#Final note 
```{r}
DATA[DATA$Temperature==999.9,"Temperature"] <- NA

str(DATA)

hist(DATA$Temperature, main="Temperature")

```





